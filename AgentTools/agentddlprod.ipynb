{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64ccac34-bb2b-46cf-91b0-4cefa0ca718b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog_name\", \"\", \"Catalog (required)\")\n",
    "dbutils.widgets.text(\"schema_name\", \"\", \"Schema\")\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog_name\").strip()\n",
    "SCHEMA_NAME = dbutils.widgets.get(\"schema_name\").strip() or \"spark_observability\"\n",
    "\n",
    "# UC Validation\n",
    "if not CATALOG_NAME:\n",
    "    raise ValueError(\"catalog widget must point to an existing catalog\")\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0325a115-6ef0-439e-a408-d14515f2ba39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG IDENTIFIER(:catalog_name);\n",
    "USE SCHEMA IDENTIFIER(:schema_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e7b29d7-cb5b-40a9-8933-b243bb022d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getsparkcontext(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls to db api to get spark context'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'clusterapi',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"api/2.1/clusters/get?cluster_id=%s\", clusterid))\n",
    "    )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "105b06c7-6024-4227-98cd-315b77387e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listappsraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to list applications submitted against spark cluster'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications\", clusterid, getsparkcontext(clusterid):spark_context_id),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "788d56aa-f380-4a46-8b33-36b5c7f06520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getappid(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get appid'\n",
    "RETURN try_parse_json(listappsraw(clusterid))::array<struct<id:string>>[0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad728d1-557f-4cd4-b909-3e02cf2e1422",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshsjobsraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get jobs list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/jobs\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcc24c31-fa04-4716-89c1-e1fc59f964fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshsstagesraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get stages list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/stages\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f984d94d-3308-4454-a067-2a5cf9cc9999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshssqlraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get sql list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/sql\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02cb1e5d-bf68-486d-b4b7-c58ce6012d83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshsexecutorsraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get executors list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/allexecutors\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3f542aa-494d-4e21-810b-2ef6712801a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshsenvraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get environment raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/environment\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5097d68-99e3-4499-ba72-1341c89a1ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshstasksraw(\n",
    "  clusterid string, stageid int\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get tasks list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/stages/%s/0/taskSummary\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid), stageid),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c814473-efe4-426b-9561-4a3992399ed3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1766855302483}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--list jobs mcp tool\n",
    "CREATE OR REPLACE FUNCTION getslowestjobs(\n",
    "  clusterid string\n",
    ")\n",
    "\n",
    "RETURNS TABLE (jobId string, name string, description string, submissionTime string, completionTime string, stageIds string, status string, numTasks double, numCompletedTasks double, numSkippedTasks double, numFailedTasks double, numCompletedStages double, numSkippedStages double, numFailedStages double, runtimesec long)\n",
    "COMMENT 'Calls shs to get slowestjobs'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshsjobsraw(clusterid))::array<struct<jobId:string, name:string, description:string, submissionTime:string, completionTime:string, stageIds:string, status:string, numTasks:double, numCompletedTasks:double, numSkippedTasks:double, numFailedTasks:double, numCompletedStages:double, numSkippedStages:double, numFailedStages:double>> as jobmetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(jobmetrics) as jobmetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select jobmetricsexp.*,\n",
    "timestampdiff(second, to_timestamp(jobmetricsexp.submissionTime), to_timestamp(jobmetricsexp.completionTime)) as runtimesec\n",
    "from explode \n",
    "order by runtimesec desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f30398d7-e3a2-422c-aa32-2d4ad660c7c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getsloweststages(\n",
    "  clusterid string\n",
    ")\n",
    "\n",
    "RETURNS TABLE (stageId string, attemptId string, name string, description string, submissionTime string, completionTime string, status string, numTasks double, numCompletedTasks double, numSkippedTasks double, numFailedTasks double, numCompletedStages double, numSkippedStages double, numFailedStages double, memoryBytesSpilled long, diskBytesSpilled long, inputBytes long, inputRecords long, outputBytes long, outputRecords long, shuffleReadBytes long, shuffleReadRecords long, shuffleWriteBytes long, shuffleWriteRecords long, runtimesec long)\n",
    "COMMENT 'Calls shs to get slowest stages'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshsstagesraw(clusterid))::array<struct<stageId:string, attemptId:string, name:string, description:string, submissionTime:string, completionTime:string, status:string, numTasks:double, numCompletedTasks:double, numSkippedTasks:double, numFailedTasks:double, numCompletedStages:double, numSkippedStages:double, numFailedStages:double, memoryBytesSpilled:long, diskBytesSpilled:long, inputBytes:long, inputRecords:long, outputBytes:long, outputRecords:long, shuffleReadBytes:long, shuffleReadRecords:long, shuffleWriteBytes:long, shuffleWriteRecords:long >> as stagemetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(stagemetrics) as stagemetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select stagemetricsexp.*,\n",
    "timestampdiff(second, to_timestamp(stagemetricsexp.submissionTime), to_timestamp(stagemetricsexp.completionTime)) as runtimesec\n",
    "from explode \n",
    "order by runtimesec desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1815a1-e592-40c5-8b46-89509c7bdc11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--list jobs mcp tool\n",
    "CREATE OR REPLACE FUNCTION getslowestsql(\n",
    "  clusterid string\n",
    ")\n",
    "\n",
    "RETURNS TABLE (id long, status string, description string, planDescription string, submissionTime string, duration long, successJobIds string, failedJobIds string, nodes array<struct<nodeId: INT, nodeName: STRING, metrics: array<struct<name:STRING, value:STRING>>>>)\n",
    "COMMENT 'Calls shs to get slowest sql queries'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshssqlraw(clusterid))::array<struct<id:long, status:string, description:string, planDescription:string, submissionTime:string, duration:long, successJobIds:string, failedJobIds:string, nodes: array<struct<nodeId: INT, nodeName: STRING, metrics: array<struct<name:STRING, value:STRING>>>> >> as sqlmetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(sqlmetrics) as sqlmetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select sqlmetricsexp.*\n",
    "from explode \n",
    "order by sqlmetricsexp.duration desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6677d367-9ac6-4f0a-a95a-e0616119799f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--list jobs mcp tool\n",
    "CREATE OR REPLACE FUNCTION getstage(\n",
    "  clusterid string, stageid int\n",
    ")\n",
    "\n",
    "RETURNS TABLE (stageId string, attemptId string, name string, description string, submissionTime string, completionTime string, status string, numTasks double, numCompletedTasks double, numSkippedTasks double, numFailedTasks double, numCompletedStages double, numSkippedStages double, numFailedStages double, memoryBytesSpilled long, diskBytesSpilled long, inputBytes long, inputRecords long, outputBytes long, outputRecords long, shuffleReadBytes long, shuffleReadRecords long, shuffleWriteBytes long, shuffleWriteRecords long, runtimesec long)\n",
    "COMMENT 'Calls shs to get a specific stage'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshsstagesraw(clusterid))::array<struct<stageId:string, attemptId:string, name:string, description:string, submissionTime:string, completionTime:string, status:string, numTasks:double, numCompletedTasks:double, numSkippedTasks:double, numFailedTasks:double, numCompletedStages:double, numSkippedStages:double, numFailedStages:double, memoryBytesSpilled:long, diskBytesSpilled:long, inputBytes:long, inputRecords:long, outputBytes:long, outputRecords:long, shuffleReadBytes:long, shuffleReadRecords:long, shuffleWriteBytes:long, shuffleWriteRecords:long >> as stagemetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(stagemetrics) as stagemetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select stagemetricsexp.*,\n",
    "timestampdiff(second, to_timestamp(stagemetricsexp.submissionTime), to_timestamp(stagemetricsexp.completionTime)) as runtimesec\n",
    "from explode \n",
    "where stagemetricsexp.stageId = stageid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d16ba4d-3c3a-4b67-8545-7b1c11578106",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--list jobs mcp tool\n",
    "CREATE OR REPLACE FUNCTION getexecutor(\n",
    "  clusterid string, executorid int\n",
    ")\n",
    "\n",
    "RETURNS TABLE (id string, memoryUsed double, diskUsed double, totalCores double, addTime string, removeTime string, maxTasks double, completedTasks double, totalTasks double, totalDuration double, totalGCTime double, totalInputBytes long, totalShuffleRead long, totalShuffleWrite long, maxMemory long, uptime long)\n",
    "COMMENT 'Calls shs to get a specific executor'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshsexecutorsraw(clusterid))::array<struct<id:string, memoryUsed:double, diskUsed:double, totalCores:double, addTime:string, removeTime:string, maxTasks:double, completedTasks:double, totalTasks:double, totalDuration:double, totalGCTime:double, totalInputBytes:long, totalShuffleRead:long, totalShuffleWrite:long, maxMemory:long >> as execmetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(execmetrics) as execmetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select execmetricsexp.*,\n",
    "timestampdiff(second, to_timestamp(execmetricsexp.addTime), to_timestamp(execmetricsexp.removeTime)) as uptime\n",
    "from explode \n",
    "where execmetricsexp.id = executorid"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7680324554721234,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "agentddlprod",
   "widgets": {
    "catalog_name": {
     "currentValue": "prodrs",
     "nuid": "4a47c85c-f032-4fb1-93e5-7fadafb81c9e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Catalog (required)",
      "name": "catalog_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "Catalog (required)",
      "name": "catalog_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "schema_name": {
     "currentValue": "spark_observability_dev",
     "nuid": "af0f3750-cc6f-46ba-b0ba-d58d615ac1b7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Schema",
      "name": "schema_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "Schema",
      "name": "schema_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
