{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64ccac34-bb2b-46cf-91b0-4cefa0ca718b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog_name\", \"\", \"Catalog (required)\")\n",
    "dbutils.widgets.text(\"schema_name\", \"\", \"Schema\")\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog_name\").strip()\n",
    "SCHEMA_NAME = dbutils.widgets.get(\"schema_name\").strip() or \"spark_observability\"\n",
    "\n",
    "# UC Validation\n",
    "if not CATALOG_NAME:\n",
    "    raise ValueError(\"catalog widget must point to an existing catalog\")\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0325a115-6ef0-439e-a408-d14515f2ba39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG IDENTIFIER(:catalog_name);\n",
    "USE SCHEMA IDENTIFIER(:schema_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e7b29d7-cb5b-40a9-8933-b243bb022d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION clustermetrics(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls to db api to get spark context'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'clusterapi',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"api/2.1/clusters/get?cluster_id=%s\", clusterid))\n",
    "    )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "105b06c7-6024-4227-98cd-315b77387e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listappsraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to list applications submitted against spark cluster'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications\", clusterid, getsparkcontext(clusterid):spark_context_id),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "788d56aa-f380-4a46-8b33-36b5c7f06520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getappid(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get appid'\n",
    "RETURN try_parse_json(listappsraw(clusterid))::array<struct<id:string>>[0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad728d1-557f-4cd4-b909-3e02cf2e1422",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshsjobsraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get jobs list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/jobs\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcc24c31-fa04-4716-89c1-e1fc59f964fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshsstagesraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get stages list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/stages\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f984d94d-3308-4454-a067-2a5cf9cc9999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshssqlraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get sql list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/sql\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02cb1e5d-bf68-486d-b4b7-c58ce6012d83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshsexecutorsraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get executors list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/allexecutors\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3f542aa-494d-4e21-810b-2ef6712801a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshsenvraw(\n",
    "  clusterid string\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get environment raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/environment\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid)),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5097d68-99e3-4499-ba72-1341c89a1ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION listshstasksraw(\n",
    "  clusterid string, stageid int\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Calls shs to get tasks list raw'\n",
    "RETURN (\n",
    "  http_request(\n",
    "  conn => 'shsjobs',\n",
    "  method => 'GET',\n",
    "  path => format_string(\"sparkui/%s/driver-%s/api/v1/applications/%s/stages/%s/0/taskSummary\", clusterid, getsparkcontext(clusterid):spark_context_id, getappid(clusterid), stageid),\n",
    "   headers => map(\n",
    "       'Cookie', format_string(\"DATAPLANE_DOMAIN_DBAUTH=%s\", secret(\"shscreds\", \"cookies\")))\n",
    "    )\n",
    "  )\n",
    ".text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7807d8d3-ab4c-4412-8a22-ed2ab23fe99c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getslowestjobs(\n",
    "  clusterid string\n",
    ")\n",
    "\n",
    "RETURNS TABLE (jobId string, name string, description string, submissionTime string, completionTime string, stageIds string, status string, numTasks double, numCompletedTasks double, numSkippedTasks double, numFailedTasks double, numCompletedStages double, numSkippedStages double, numFailedStages double, runtimesec long)\n",
    "COMMENT 'Calls shs to get slowestjobs'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshsjobsraw(clusterid))::array<struct<jobId:string, name:string, description:string, submissionTime:string, completionTime:string, stageIds:string, status:string, numTasks:double, numCompletedTasks:double, numSkippedTasks:double, numFailedTasks:double, numCompletedStages:double, numSkippedStages:double, numFailedStages:double>> as jobmetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(jobmetrics) as jobmetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select jobmetricsexp.*,\n",
    "timestampdiff(second, to_timestamp(jobmetricsexp.submissionTime), to_timestamp(jobmetricsexp.completionTime)) as runtimesec\n",
    "from explode \n",
    "order by runtimesec desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f30398d7-e3a2-422c-aa32-2d4ad660c7c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getsloweststages(\n",
    "  clusterid string\n",
    ")\n",
    "\n",
    "RETURNS TABLE (stageId string, attemptId string, name string, description string, submissionTime string, completionTime string, status string, numTasks double, numCompletedTasks double, numSkippedTasks double, numFailedTasks double, numCompletedStages double, numSkippedStages double, numFailedStages double, memoryBytesSpilled long, diskBytesSpilled long, inputBytes long, inputRecords long, outputBytes long, outputRecords long, shuffleReadBytes long, shuffleReadRecords long, shuffleWriteBytes long, shuffleWriteRecords long, runtimesec long)\n",
    "COMMENT 'Calls shs to get slowest stages'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshsstagesraw(clusterid))::array<struct<stageId:string, attemptId:string, name:string, description:string, submissionTime:string, completionTime:string, status:string, numTasks:double, numCompletedTasks:double, numSkippedTasks:double, numFailedTasks:double, numCompletedStages:double, numSkippedStages:double, numFailedStages:double, memoryBytesSpilled:long, diskBytesSpilled:long, inputBytes:long, inputRecords:long, outputBytes:long, outputRecords:long, shuffleReadBytes:long, shuffleReadRecords:long, shuffleWriteBytes:long, shuffleWriteRecords:long >> as stagemetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(stagemetrics) as stagemetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select stagemetricsexp.*,\n",
    "timestampdiff(second, to_timestamp(stagemetricsexp.submissionTime), to_timestamp(stagemetricsexp.completionTime)) as runtimesec\n",
    "from explode \n",
    "order by runtimesec desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1815a1-e592-40c5-8b46-89509c7bdc11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getslowestsql(\n",
    "  clusterid string\n",
    ")\n",
    "\n",
    "RETURNS TABLE (id long, status string, description string, planDescription string, submissionTime string, duration long, successJobIds string, failedJobIds string, nodes array<struct<nodeId: INT, nodeName: STRING, metrics: array<struct<name:STRING, value:STRING>>>>)\n",
    "COMMENT 'Calls shs to get slowest sql queries'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshssqlraw(clusterid))::array<struct<id:long, status:string, description:string, planDescription:string, submissionTime:string, duration:long, successJobIds:string, failedJobIds:string, nodes: array<struct<nodeId: INT, nodeName: STRING, metrics: array<struct<name:STRING, value:STRING>>>> >> as sqlmetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(sqlmetrics) as sqlmetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select sqlmetricsexp.*\n",
    "from explode \n",
    "order by sqlmetricsexp.duration desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6677d367-9ac6-4f0a-a95a-e0616119799f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getstage(\n",
    "  clusterid string, stageid int\n",
    ")\n",
    "\n",
    "RETURNS TABLE (stageId string, attemptId string, name string, description string, submissionTime string, completionTime string, status string, numTasks double, numCompletedTasks double, numSkippedTasks double, numFailedTasks double, numCompletedStages double, numSkippedStages double, numFailedStages double, memoryBytesSpilled long, diskBytesSpilled long, inputBytes long, inputRecords long, outputBytes long, outputRecords long, shuffleReadBytes long, shuffleReadRecords long, shuffleWriteBytes long, shuffleWriteRecords long, runtimesec long)\n",
    "COMMENT 'Calls shs to get a specific stage'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshsstagesraw(clusterid))::array<struct<stageId:string, attemptId:string, name:string, description:string, submissionTime:string, completionTime:string, status:string, numTasks:double, numCompletedTasks:double, numSkippedTasks:double, numFailedTasks:double, numCompletedStages:double, numSkippedStages:double, numFailedStages:double, memoryBytesSpilled:long, diskBytesSpilled:long, inputBytes:long, inputRecords:long, outputBytes:long, outputRecords:long, shuffleReadBytes:long, shuffleReadRecords:long, shuffleWriteBytes:long, shuffleWriteRecords:long >> as stagemetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(stagemetrics) as stagemetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select stagemetricsexp.*,\n",
    "timestampdiff(second, to_timestamp(stagemetricsexp.submissionTime), to_timestamp(stagemetricsexp.completionTime)) as runtimesec\n",
    "from explode \n",
    "where stagemetricsexp.stageId = stageid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d16ba4d-3c3a-4b67-8545-7b1c11578106",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION getexecutor(\n",
    "  clusterid string, executorid int\n",
    ")\n",
    "\n",
    "RETURNS TABLE (id string, memoryUsed double, diskUsed double, totalCores double, addTime string, removeTime string, maxTasks double, completedTasks double, totalTasks double, totalDuration double, totalGCTime double, totalInputBytes long, totalShuffleRead long, totalShuffleWrite long, maxMemory long, uptime long)\n",
    "COMMENT 'Calls shs to get a specific executor'\n",
    "RETURN\n",
    "\n",
    "with raw as (\n",
    "  select try_parse_json(listshsexecutorsraw(clusterid))::array<struct<id:string, memoryUsed:double, diskUsed:double, totalCores:double, addTime:string, removeTime:string, maxTasks:double, completedTasks:double, totalTasks:double, totalDuration:double, totalGCTime:double, totalInputBytes:long, totalShuffleRead:long, totalShuffleWrite:long, maxMemory:long >> as execmetrics),\n",
    "\n",
    "explode as (\n",
    "  select explode(execmetrics) as execmetricsexp\n",
    "  from raw\n",
    ")\n",
    "\n",
    "select execmetricsexp.*,\n",
    "timestampdiff(second, to_timestamp(execmetricsexp.addTime), to_timestamp(execmetricsexp.removeTime)) as uptime\n",
    "from explode \n",
    "where execmetricsexp.id = executorid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0560cde5-94ba-4db1-a384-046c65ab76fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- RSTODO-- can we ref token + wsurl w/ secrets instead? why do we need WSID?\n",
    "\n",
    "CREATE OR REPLACE FUNCTION py_listshsjobsraw(cluster_id STRING)\n",
    "RETURNS STRING\n",
    "LANGUAGE PYTHON\n",
    "-- update with your service credential name\n",
    "AS $$\n",
    "import requests, base64, json, re\n",
    "from databricks.sdk import WorkspaceClient \n",
    "\n",
    "def safe_b64_decode(val):\n",
    "    if not val: return val\n",
    "    try: return base64.b64decode(val).decode('utf-8') if not val.startswith(\"http\") else val\n",
    "    except: return val\n",
    "\n",
    "try:\n",
    "    # 1. AUTH & CLIENT\n",
    "    token = w.secrets.get_secret(scope=\"shscreds\", key=\"token\").value\n",
    "    cp_url = w.secrets.get_secret(scope=\"shscreds\", key=\"wsurl\").value\n",
    "    w = WorkspaceClient(host=cp_url, token=pat_token)\n",
    "\n",
    "    # 2. DYNAMICALLY RESOLVE VARIABLES\n",
    "    \n",
    "    # A. Workspace ID\n",
    "    try:\n",
    "        match = re.search(r'adb-(\\d+)', cp_url)\n",
    "        if match:\n",
    "            ws_id = match.group(1)\n",
    "        else:\n",
    "            ws_id = w.secrets.get_secret(scope=\"shscreds\", key=\"workspace_id\").value\n",
    "    except Exception:\n",
    "        return json.dumps({\"error\": \"Could not derive Workspace ID from CP_URL or secrets\"})\n",
    "\n",
    "    # B. Data Plane URL\n",
    "    try:\n",
    "        raw_dp_url_val = w.secrets.get_secret(scope=\"shscreds\", key=\"dpurl\").value\n",
    "        dp_url = safe_b64_decode(raw_dp_url_val).strip().rstrip('/')\n",
    "    except Exception:\n",
    "        return json.dumps({\"error\": \"Missing secret: shscreds/dpurl\"})\n",
    "\n",
    "    # C. Auth Cookies\n",
    "    raw_cookie = w.secrets.get_secret(scope=\"shscreds\", key=\"cookies\").value\n",
    "    cookies = {'DATAPLANE_DOMAIN_DBAUTH': safe_b64_decode(raw_cookie)}\n",
    "    \n",
    "    # 3. IDENTIFY APP\n",
    "    params = {\"o\": ws_id}\n",
    "    \n",
    "    c_info = w.clusters.get(cluster_id=cluster_id)\n",
    "    ctx_id = str(c_info.spark_context_id)\n",
    "    ctx_id = ctx_id if ctx_id.startswith(\"driver-\") else f\"driver-{ctx_id}\"\n",
    "    \n",
    "    api_base = f\"{dp_url}/sparkui/{cluster_id}/{ctx_id}/api/v1/applications\"\n",
    "    \n",
    "    # 4. FETCH DATA\n",
    "    apps = requests.get(api_base, params=params, cookies=cookies).json()\n",
    "    if not apps:\n",
    "         return json.dumps({\"error\": \"No applications found for this cluster\"})\n",
    "         \n",
    "    app_id = apps[0]['id']\n",
    "\n",
    "    sql_url = f\"{api_base}/{app_id}/sql\"\n",
    "    raw_sql_data = requests.get(sql_url, params={**params, \"length\": 100}, cookies=cookies).json()\n",
    "\n",
    "    # 5. SANITIZATION\n",
    "    sanitized_data = []\n",
    "    for entry in raw_sql_data:\n",
    "        entry.pop('physicalPlanDescription', None) \n",
    "        if 'description' in entry:\n",
    "            entry['description'] = entry['description'].replace('\\n', ' ').replace('\\r', ' ')[:200]\n",
    "        sanitized_data.append(entry)\n",
    "\n",
    "    return json.dumps(sanitized_data, separators=(',', ':'))\n",
    "\n",
    "except Exception as e:\n",
    "    return json.dumps({\"error\": f\"UDF Error: {str(e)}\"})\n",
    "$$;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5147106489636002,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "UpstreamFunctionsDbx",
   "widgets": {
    "catalog_name": {
     "currentValue": "prodrs",
     "nuid": "4a47c85c-f032-4fb1-93e5-7fadafb81c9e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Catalog (required)",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Catalog (required)",
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "spark_observability",
     "nuid": "af0f3750-cc6f-46ba-b0ba-d58d615ac1b7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Schema",
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Schema",
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
